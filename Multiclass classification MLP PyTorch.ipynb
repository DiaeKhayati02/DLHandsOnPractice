{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa1d9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5a19481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset definition\n",
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(path, header=None)\n",
    "        # store the inputs and outputs\n",
    "        self.X = df.iloc[:, 1:-1].values.astype('float32')\n",
    "        self.y = df.iloc[:, -1].values\n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')\n",
    "        # label encode target and ensure the values are floats\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ad79132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # third hidden layer and output\n",
    "        self.hidden3 = Linear(8, 3)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Softmax(dim=1)\n",
    "\n",
    "        # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # output layer\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f29edc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset\n",
    "def prepare_data(path):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da5d3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_model(train_dl, model):\n",
    "    size = len(train_dl.dataset)\n",
    "    # define the optimization\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "        # enumerate epochs\n",
    "    for epoch in tqdm(range(100),desc='Training Epochs'):\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "        # enumerate mini batches\n",
    "        for batch, (inputs, targets) in enumerate(train_dl):\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "            #if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(inputs)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46bbf587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        # convert to class labels\n",
    "        yhat = argmax(yhat, axis=1)\n",
    "        # reshape for stacking\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        yhat = yhat.reshape((len(yhat), 1))\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edc5bf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a class prediction for one row of data\n",
    "def predict(row, model):\n",
    "# convert row to data\n",
    "    row = Tensor([row])\n",
    "    # make prediction\n",
    "    yhat = model(row)\n",
    "    # retrieve numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "476b025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  14%|█▍        | 14/100 [00:00<00:00, 138.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.225657 [    0/  100]\n",
      "loss: 1.036347 [   32/  100]\n",
      "loss: 1.118782 [   64/  100]\n",
      "loss: 0.825049 [   12/  100]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.976485 [    0/  100]\n",
      "loss: 0.956556 [   32/  100]\n",
      "loss: 0.955060 [   64/  100]\n",
      "loss: 1.218741 [   12/  100]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.933215 [    0/  100]\n",
      "loss: 0.951111 [   32/  100]\n",
      "loss: 0.984698 [   64/  100]\n",
      "loss: 0.656158 [   12/  100]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.020600 [    0/  100]\n",
      "loss: 0.925341 [   32/  100]\n",
      "loss: 0.865654 [   64/  100]\n",
      "loss: 0.826126 [   12/  100]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.984448 [    0/  100]\n",
      "loss: 0.819578 [   32/  100]\n",
      "loss: 0.922507 [   64/  100]\n",
      "loss: 0.811416 [   12/  100]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.031016 [    0/  100]\n",
      "loss: 0.782442 [   32/  100]\n",
      "loss: 0.885972 [   64/  100]\n",
      "loss: 1.027918 [   12/  100]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.912448 [    0/  100]\n",
      "loss: 0.972833 [   32/  100]\n",
      "loss: 0.812113 [   64/  100]\n",
      "loss: 0.811919 [   12/  100]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.004170 [    0/  100]\n",
      "loss: 0.827903 [   32/  100]\n",
      "loss: 0.892621 [   64/  100]\n",
      "loss: 0.558334 [   12/  100]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.890828 [    0/  100]\n",
      "loss: 0.795781 [   32/  100]\n",
      "loss: 0.981112 [   64/  100]\n",
      "loss: 1.050039 [   12/  100]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.951480 [    0/  100]\n",
      "loss: 0.796959 [   32/  100]\n",
      "loss: 0.946120 [   64/  100]\n",
      "loss: 0.783941 [   12/  100]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.890718 [    0/  100]\n",
      "loss: 0.997733 [   32/  100]\n",
      "loss: 0.825794 [   64/  100]\n",
      "loss: 0.581432 [   12/  100]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.882506 [    0/  100]\n",
      "loss: 0.937330 [   32/  100]\n",
      "loss: 0.894334 [   64/  100]\n",
      "loss: 0.563703 [   12/  100]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.942183 [    0/  100]\n",
      "loss: 0.855226 [   32/  100]\n",
      "loss: 0.889062 [   64/  100]\n",
      "loss: 0.794545 [   12/  100]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.940485 [    0/  100]\n",
      "loss: 0.828573 [   32/  100]\n",
      "loss: 0.885418 [   64/  100]\n",
      "loss: 1.053350 [   12/  100]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.714508 [    0/  100]\n",
      "loss: 1.027977 [   32/  100]\n",
      "loss: 0.941826 [   64/  100]\n",
      "loss: 0.781211 [   12/  100]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.890676 [    0/  100]\n",
      "loss: 1.026209 [   32/  100]\n",
      "loss: 0.766665 [   64/  100]\n",
      "loss: 0.789691 [   12/  100]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.891991 [    0/  100]\n",
      "loss: 0.854610 [   32/  100]\n",
      "loss: 0.937597 [   64/  100]\n",
      "loss: 0.790060 [   12/  100]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.026336 [    0/  100]\n",
      "loss: 0.800066 [   32/  100]\n",
      "loss: 0.884983 [   64/  100]\n",
      "loss: 0.555485 [   12/  100]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.907966 [    0/  100]\n",
      "loss: 0.793695 [   32/  100]\n",
      "loss: 0.888469 [   64/  100]\n",
      "loss: 1.518748 [   12/  100]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.821796 [    0/  100]\n",
      "loss: 0.894186 [   32/  100]\n",
      "loss: 0.994126 [   64/  100]\n",
      "loss: 0.556864 [   12/  100]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.849931 [    0/  100]\n",
      "loss: 0.867497 [   32/  100]\n",
      "loss: 0.965739 [   64/  100]\n",
      "loss: 0.787621 [   12/  100]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.745607 [    0/  100]\n",
      "loss: 1.024918 [   32/  100]\n",
      "loss: 0.853124 [   64/  100]\n",
      "loss: 1.250093 [   12/  100]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.862565 [    0/  100]\n",
      "loss: 0.902221 [   32/  100]\n",
      "loss: 0.888521 [   64/  100]\n",
      "loss: 1.003672 [   12/  100]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.941203 [    0/  100]\n",
      "loss: 0.903099 [   32/  100]\n",
      "loss: 0.775965 [   64/  100]\n",
      "loss: 1.271701 [   12/  100]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.822248 [    0/  100]\n",
      "loss: 0.961973 [   32/  100]\n",
      "loss: 0.921091 [   64/  100]\n",
      "loss: 0.575764 [   12/  100]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.861537 [    0/  100]\n",
      "loss: 0.880830 [   32/  100]\n",
      "loss: 0.970667 [   64/  100]\n",
      "loss: 0.554104 [   12/  100]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.858240 [    0/  100]\n",
      "loss: 0.793827 [   32/  100]\n",
      "loss: 1.032864 [   64/  100]\n",
      "loss: 0.792059 [   12/  100]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.885187 [    0/  100]\n",
      "loss: 0.969914 [   32/  100]\n",
      "loss: 0.824442 [   64/  100]\n",
      "loss: 0.805016 [   12/  100]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.907526 [    0/  100]\n",
      "loss: 0.859264 [   32/  100]\n",
      "loss: 0.910079 [   64/  100]\n",
      "loss: 0.796853 [   12/  100]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.862787 [    0/  100]\n",
      "loss: 0.913598 [   32/  100]\n",
      "loss: 0.902822 [   64/  100]\n",
      "loss: 0.782301 [   12/  100]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.935468 [    0/  100]\n",
      "loss: 0.903309 [   32/  100]\n",
      "loss: 0.839655 [   64/  100]\n",
      "loss: 0.782785 [   12/  100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  47%|████▋     | 47/100 [00:00<00:00, 142.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.907809 [    0/  100]\n",
      "loss: 0.890174 [   32/  100]\n",
      "loss: 0.876183 [   64/  100]\n",
      "loss: 0.800628 [   12/  100]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.847796 [    0/  100]\n",
      "loss: 0.854638 [   32/  100]\n",
      "loss: 0.941943 [   64/  100]\n",
      "loss: 1.035759 [   12/  100]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.827518 [    0/  100]\n",
      "loss: 0.877930 [   32/  100]\n",
      "loss: 0.967545 [   64/  100]\n",
      "loss: 0.801450 [   12/  100]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.857170 [    0/  100]\n",
      "loss: 0.935501 [   32/  100]\n",
      "loss: 0.881703 [   64/  100]\n",
      "loss: 0.788688 [   12/  100]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.906653 [    0/  100]\n",
      "loss: 0.859407 [   32/  100]\n",
      "loss: 0.879537 [   64/  100]\n",
      "loss: 1.031815 [   12/  100]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.776348 [    0/  100]\n",
      "loss: 0.849162 [   32/  100]\n",
      "loss: 1.025154 [   64/  100]\n",
      "loss: 1.015498 [   12/  100]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.879850 [    0/  100]\n",
      "loss: 0.943939 [   32/  100]\n",
      "loss: 0.849445 [   64/  100]\n",
      "loss: 0.791039 [   12/  100]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.827421 [    0/  100]\n",
      "loss: 0.967186 [   32/  100]\n",
      "loss: 0.878083 [   64/  100]\n",
      "loss: 0.788454 [   12/  100]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.912212 [    0/  100]\n",
      "loss: 0.933611 [   32/  100]\n",
      "loss: 0.765649 [   64/  100]\n",
      "loss: 1.271234 [   12/  100]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.825516 [    0/  100]\n",
      "loss: 0.915324 [   32/  100]\n",
      "loss: 0.932208 [   64/  100]\n",
      "loss: 0.786029 [   12/  100]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.822267 [    0/  100]\n",
      "loss: 0.944426 [   32/  100]\n",
      "loss: 0.876517 [   64/  100]\n",
      "loss: 1.018322 [   12/  100]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.848712 [    0/  100]\n",
      "loss: 0.883792 [   32/  100]\n",
      "loss: 0.910118 [   64/  100]\n",
      "loss: 1.015678 [   12/  100]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.850626 [    0/  100]\n",
      "loss: 0.905666 [   32/  100]\n",
      "loss: 0.938567 [   64/  100]\n",
      "loss: 0.599268 [   12/  100]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.970414 [    0/  100]\n",
      "loss: 0.788736 [   32/  100]\n",
      "loss: 0.942961 [   64/  100]\n",
      "loss: 0.571999 [   12/  100]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.973856 [    0/  100]\n",
      "loss: 0.826142 [   32/  100]\n",
      "loss: 0.914510 [   64/  100]\n",
      "loss: 0.562559 [   12/  100]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.946997 [    0/  100]\n",
      "loss: 0.949839 [   32/  100]\n",
      "loss: 0.795938 [   64/  100]\n",
      "loss: 0.778721 [   12/  100]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.919314 [    0/  100]\n",
      "loss: 0.910833 [   32/  100]\n",
      "loss: 0.886426 [   64/  100]\n",
      "loss: 0.554520 [   12/  100]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.885941 [    0/  100]\n",
      "loss: 0.824574 [   32/  100]\n",
      "loss: 0.932260 [   64/  100]\n",
      "loss: 1.033687 [   12/  100]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.876130 [    0/  100]\n",
      "loss: 0.910188 [   32/  100]\n",
      "loss: 0.875038 [   64/  100]\n",
      "loss: 0.814359 [   12/  100]\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.939120 [    0/  100]\n",
      "loss: 0.790433 [   32/  100]\n",
      "loss: 0.962996 [   64/  100]\n",
      "loss: 0.552069 [   12/  100]\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.017694 [    0/  100]\n",
      "loss: 0.818023 [   32/  100]\n",
      "loss: 0.825010 [   64/  100]\n",
      "loss: 0.780530 [   12/  100]\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.873374 [    0/  100]\n",
      "loss: 0.904807 [   32/  100]\n",
      "loss: 0.851521 [   64/  100]\n",
      "loss: 1.008205 [   12/  100]\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.899748 [    0/  100]\n",
      "loss: 0.901369 [   32/  100]\n",
      "loss: 0.879925 [   64/  100]\n",
      "loss: 0.554507 [   12/  100]\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.867606 [    0/  100]\n",
      "loss: 0.926057 [   32/  100]\n",
      "loss: 0.822538 [   64/  100]\n",
      "loss: 1.031761 [   12/  100]\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.866473 [    0/  100]\n",
      "loss: 0.903185 [   32/  100]\n",
      "loss: 0.865360 [   64/  100]\n",
      "loss: 0.831794 [   12/  100]\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.951458 [    0/  100]\n",
      "loss: 0.842323 [   32/  100]\n",
      "loss: 0.811801 [   64/  100]\n",
      "loss: 1.002215 [   12/  100]\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.841882 [    0/  100]\n",
      "loss: 0.949800 [   32/  100]\n",
      "loss: 0.809578 [   64/  100]\n",
      "loss: 1.000511 [   12/  100]\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.888970 [    0/  100]\n",
      "loss: 0.905225 [   32/  100]\n",
      "loss: 0.800292 [   64/  100]\n",
      "loss: 0.765292 [   12/  100]\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.817389 [    0/  100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  77%|███████▋  | 77/100 [00:00<00:00, 141.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.924268 [   32/  100]\n",
      "loss: 0.814249 [   64/  100]\n",
      "loss: 0.785550 [   12/  100]\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.869279 [    0/  100]\n",
      "loss: 0.831930 [   32/  100]\n",
      "loss: 0.786589 [   64/  100]\n",
      "loss: 0.718674 [   12/  100]\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.784968 [    0/  100]\n",
      "loss: 0.826048 [   32/  100]\n",
      "loss: 0.768964 [   64/  100]\n",
      "loss: 0.836416 [   12/  100]\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.742478 [    0/  100]\n",
      "loss: 0.760486 [   32/  100]\n",
      "loss: 0.804878 [   64/  100]\n",
      "loss: 0.810441 [   12/  100]\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.731596 [    0/  100]\n",
      "loss: 0.801129 [   32/  100]\n",
      "loss: 0.740474 [   64/  100]\n",
      "loss: 0.764075 [   12/  100]\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.761563 [    0/  100]\n",
      "loss: 0.741051 [   32/  100]\n",
      "loss: 0.754640 [   64/  100]\n",
      "loss: 0.867577 [   12/  100]\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.734542 [    0/  100]\n",
      "loss: 0.694592 [   32/  100]\n",
      "loss: 0.778426 [   64/  100]\n",
      "loss: 0.865678 [   12/  100]\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.743800 [    0/  100]\n",
      "loss: 0.757876 [   32/  100]\n",
      "loss: 0.797614 [   64/  100]\n",
      "loss: 0.690660 [   12/  100]\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.707450 [    0/  100]\n",
      "loss: 0.706576 [   32/  100]\n",
      "loss: 0.750133 [   64/  100]\n",
      "loss: 0.720035 [   12/  100]\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.703980 [    0/  100]\n",
      "loss: 0.759551 [   32/  100]\n",
      "loss: 0.802063 [   64/  100]\n",
      "loss: 0.703520 [   12/  100]\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.735801 [    0/  100]\n",
      "loss: 0.787851 [   32/  100]\n",
      "loss: 0.694512 [   64/  100]\n",
      "loss: 0.714885 [   12/  100]\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.738201 [    0/  100]\n",
      "loss: 0.675716 [   32/  100]\n",
      "loss: 0.730318 [   64/  100]\n",
      "loss: 0.974053 [   12/  100]\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.715580 [    0/  100]\n",
      "loss: 0.671650 [   32/  100]\n",
      "loss: 0.696840 [   64/  100]\n",
      "loss: 0.677177 [   12/  100]\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.747308 [    0/  100]\n",
      "loss: 0.757447 [   32/  100]\n",
      "loss: 0.755899 [   64/  100]\n",
      "loss: 0.743722 [   12/  100]\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.732817 [    0/  100]\n",
      "loss: 0.690306 [   32/  100]\n",
      "loss: 0.671636 [   64/  100]\n",
      "loss: 0.715098 [   12/  100]\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.732058 [    0/  100]\n",
      "loss: 0.659843 [   32/  100]\n",
      "loss: 0.719829 [   64/  100]\n",
      "loss: 0.629715 [   12/  100]\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.676221 [    0/  100]\n",
      "loss: 0.640902 [   32/  100]\n",
      "loss: 0.753501 [   64/  100]\n",
      "loss: 0.661472 [   12/  100]\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.670533 [    0/  100]\n",
      "loss: 0.676642 [   32/  100]\n",
      "loss: 0.710921 [   64/  100]\n",
      "loss: 0.612590 [   12/  100]\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.675064 [    0/  100]\n",
      "loss: 0.698437 [   32/  100]\n",
      "loss: 0.709488 [   64/  100]\n",
      "loss: 0.569364 [   12/  100]\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.673085 [    0/  100]\n",
      "loss: 0.609463 [   32/  100]\n",
      "loss: 0.695100 [   64/  100]\n",
      "loss: 0.845242 [   12/  100]\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.665400 [    0/  100]\n",
      "loss: 0.695736 [   32/  100]\n",
      "loss: 0.654160 [   64/  100]\n",
      "loss: 0.573673 [   12/  100]\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.666155 [    0/  100]\n",
      "loss: 0.622160 [   32/  100]\n",
      "loss: 0.718031 [   64/  100]\n",
      "loss: 0.716761 [   12/  100]\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.628151 [    0/  100]\n",
      "loss: 0.762514 [   32/  100]\n",
      "loss: 0.752343 [   64/  100]\n",
      "loss: 0.563976 [   12/  100]\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.827721 [    0/  100]\n",
      "loss: 0.677120 [   32/  100]\n",
      "loss: 0.705352 [   64/  100]\n",
      "loss: 0.568997 [   12/  100]\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.668420 [    0/  100]\n",
      "loss: 0.641844 [   32/  100]\n",
      "loss: 0.659752 [   64/  100]\n",
      "loss: 0.830173 [   12/  100]\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.650618 [    0/  100]\n",
      "loss: 0.637605 [   32/  100]\n",
      "loss: 0.669608 [   64/  100]\n",
      "loss: 0.783383 [   12/  100]\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.746422 [    0/  100]\n",
      "loss: 0.648496 [   32/  100]\n",
      "loss: 0.636287 [   64/  100]\n",
      "loss: 0.732915 [   12/  100]\n",
      "Epoch 87\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 100/100 [00:00<00:00, 134.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.700245 [    0/  100]\n",
      "loss: 0.661331 [   32/  100]\n",
      "loss: 0.616117 [   64/  100]\n",
      "loss: 0.718434 [   12/  100]\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.718677 [    0/  100]\n",
      "loss: 0.650289 [   32/  100]\n",
      "loss: 0.627144 [   64/  100]\n",
      "loss: 0.594709 [   12/  100]\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.643723 [    0/  100]\n",
      "loss: 0.709436 [   32/  100]\n",
      "loss: 0.659083 [   64/  100]\n",
      "loss: 0.565838 [   12/  100]\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.676741 [    0/  100]\n",
      "loss: 0.639964 [   32/  100]\n",
      "loss: 0.633888 [   64/  100]\n",
      "loss: 0.571676 [   12/  100]\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.651196 [    0/  100]\n",
      "loss: 0.655385 [   32/  100]\n",
      "loss: 0.646694 [   64/  100]\n",
      "loss: 0.573125 [   12/  100]\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.606110 [    0/  100]\n",
      "loss: 0.691662 [   32/  100]\n",
      "loss: 0.633681 [   64/  100]\n",
      "loss: 0.599855 [   12/  100]\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.670094 [    0/  100]\n",
      "loss: 0.584032 [   32/  100]\n",
      "loss: 0.655909 [   64/  100]\n",
      "loss: 0.779392 [   12/  100]\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.664715 [    0/  100]\n",
      "loss: 0.680864 [   32/  100]\n",
      "loss: 0.690519 [   64/  100]\n",
      "loss: 0.571487 [   12/  100]\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.660244 [    0/  100]\n",
      "loss: 0.698683 [   32/  100]\n",
      "loss: 0.630684 [   64/  100]\n",
      "loss: 0.586878 [   12/  100]\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.695107 [    0/  100]\n",
      "loss: 0.661201 [   32/  100]\n",
      "loss: 0.642590 [   64/  100]\n",
      "loss: 0.557692 [   12/  100]\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.669824 [    0/  100]\n",
      "loss: 0.650807 [   32/  100]\n",
      "loss: 0.680075 [   64/  100]\n",
      "loss: 0.560701 [   12/  100]\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.621137 [    0/  100]\n",
      "loss: 0.621993 [   32/  100]\n",
      "loss: 0.678155 [   64/  100]\n",
      "loss: 0.914538 [   12/  100]\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.623693 [    0/  100]\n",
      "loss: 0.607563 [   32/  100]\n",
      "loss: 0.645955 [   64/  100]\n",
      "loss: 0.761680 [   12/  100]\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.690391 [    0/  100]\n",
      "loss: 0.634692 [   32/  100]\n",
      "loss: 0.586534 [   64/  100]\n",
      "loss: 0.768015 [   12/  100]\n",
      "Accuracy: 0.960\n",
      "Predicted: [[9.9821019e-01 1.7897664e-03 2.0319066e-11]] (class=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "path = 'Iris.csv'\n",
    "train_dl, test_dl = prepare_data(path)\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))\n",
    "# define the network\n",
    "model = MLP(4)\n",
    "# train the model\n",
    "train_model(train_dl, model)\n",
    "# evaluate the model\n",
    "acc = evaluate_model(test_dl, model)\n",
    "print('Accuracy: %.3f' % acc)\n",
    "# make a single prediction\n",
    "row = [5.1,3.5,1.4,0.2]\n",
    "yhat = predict(row, model)\n",
    "print('Predicted: %s (class=%d)' % (yhat, argmax(yhat)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
